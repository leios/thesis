\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{unsrt}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {chapter}{Contents}{ii}{section*.1}\protected@file@percent }
\@writefile{toc}{\vspace  {2em}}
\@writefile{toc}{\contentsline {chapter}{Introduction}{1}{section*.3}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {1}General Purpose computing with Graphics Processing Units and the GPUE codebase}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:gpu}{{1}{1}{General Purpose computing with Graphics Processing Units and the GPUE codebase}{chapter.1}{}}
\citation{kahle2019}
\citation{gurd1988}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Types of parallelism}{2}{section.1.1}\protected@file@percent }
\citation{czechowski2012}
\citation{wittek2016}
\citation{antoine2014}
\citation{wittek2013}
\citation{garland2008,lee2010,nickolls2010}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Comparison between GPUE (CUDA), Trotter-Suzuki on both GPU (CUDA) and CPU (C++), and GPElab (Matlab). Here, it is shown that GPUE is marginally faster than Trotter-Suzuki, but both GPU implementations are faster than the CPU-based variants. Both software packages are much faster than GPElab.\relax }}{4}{figure.caption.4}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:bench}{{1.1}{4}{Comparison between GPUE (CUDA), Trotter-Suzuki on both GPU (CUDA) and CPU (C++), and GPElab (Matlab). Here, it is shown that GPUE is marginally faster than Trotter-Suzuki, but both GPU implementations are faster than the CPU-based variants. Both software packages are much faster than GPElab.\relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}General purpose computing with graphics processing units}{4}{section.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}Limitations of GPU computing}{5}{subsection.1.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.2}GPU hardware architecture}{5}{subsection.1.2.2}\protected@file@percent }
\citation{CUDAPG}
\citation{wienke2012}
\citation{chandra2001}
\citation{reyes2012}
\newlabel{lst:vecadd}{{1.1}{6}{An example of vector addition performed in C or C++ for $a$, $b$, and $c$, all of size $n$}{lstlisting.1.1}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {1.1}An example of vector addition performed in C or C++ for $a$, $b$, and $c$, all of size $n$}{6}{lstlisting.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Introduction to CUDA software interface}{6}{section*.5}\protected@file@percent }
\newlabel{lst:vecaddCUDA}{{1.2}{7}{An example of a vector addition kernel in CUDA}{lstlisting.1.2}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {1.2}An example of a vector addition kernel in CUDA}{7}{lstlisting.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces Each grid is subdivided into multiple blocks, which is further subdivided into threads for computation. Each thread has a specified ID, which acts as a one-dimensional array, even in a two or three-dimensional system. Here, all areas outlined in red have access to global memory, and any area outlined in blue has access to shared memory. \leavevmode {\color  {magenta}[slight modification necessary to show 1D indexing!]}\relax }}{9}{figure.caption.8}\protected@file@percent }
\newlabel{fig:threadsnblocks}{{1.2}{9}{Each grid is subdivided into multiple blocks, which is further subdivided into threads for computation. Each thread has a specified ID, which acts as a one-dimensional array, even in a two or three-dimensional system. Here, all areas outlined in red have access to global memory, and any area outlined in blue has access to shared memory. \jrs {slight modification necessary to show 1D indexing!}\relax }{figure.caption.8}{}}
\newlabel{lst:vecaddCUDA2}{{1.3}{10}{An example of a vector addition kernel in CUDA using blocks and threads, and ensuring no computation happens beyond the size of the array, $n$}{lstlisting.1.3}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {1.3}An example of a vector addition kernel in CUDA using blocks and threads, and ensuring no computation happens beyond the size of the array, $n$.}{10}{lstlisting.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Discussion of GPU thread and memory hierarchy}{10}{section*.11}\protected@file@percent }
\newlabel{lst:vecaddhost}{{1.4}{11}{An example of host code to run Listing~\ref {lst:vecaddCUDA2}}{lstlisting.1.4}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {1.4}An example of host code to run Listing~\ref  {lst:vecaddCUDA2}.}{11}{lstlisting.1.4}\protected@file@percent }
\citation{harris2013}
\citation{foley2017}
\citation{lonvcar2016,wang2013}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.3}Comparison between various languages for GPGPU computation}{14}{subsection.1.2.3}\protected@file@percent }
\newlabel{sec:compare}{{1.2.3}{14}{Comparison between various languages for GPGPU computation}{subsection.1.2.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{CUDA}{14}{section*.12}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{OpenCL}{14}{section*.13}\protected@file@percent }
\citation{besard2019}
\citation{bezanson2017}
\citation{besard2016,besard2018}
\@writefile{toc}{\contentsline {subsubsection}{Julia}{15}{section*.14}\protected@file@percent }
\citation{o2017}
\citation{schloss2018}
\citation{czechowski2012}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Introduction to the GPUE codebase for $n$-dimensional simulations of quantum systems on the GPU}{16}{section.1.3}\protected@file@percent }
\newlabel{sec:GPUE}{{1.3}{16}{Introduction to the GPUE codebase for $n$-dimensional simulations of quantum systems on the GPU}{section.1.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.1}FFT optimization}{17}{subsection.1.3.1}\protected@file@percent }
\citation{cohen1991,reyes2011}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.2}Dynamic field input and output in GPUE with expression trees}{18}{subsection.1.3.2}\protected@file@percent }
\newlabel{sec:expr_trees}{{1.3.2}{18}{Dynamic field input and output in GPUE with expression trees}{subsection.1.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces  Example of expression tree for $V=\frac  {1}{2}m \omega ^2 x^2 t$. Blue, filled nodes are operations, leaf nodes are variables, time has been highlighted in red, and spatially-dependent variables are in green. This visualization was modified from a form provided by Xadisten during a Twitch livestream. \relax }}{19}{figure.caption.15}\protected@file@percent }
\newlabel{fig:expr_tree}{{1.3}{19}{Example of expression tree for $V=\frac {1}{2}m \omega ^2 x^2 t$. Blue, filled nodes are operations, leaf nodes are variables, time has been highlighted in red, and spatially-dependent variables are in green. This visualization was modified from a form provided by Xadisten during a Twitch livestream. \relax }{figure.caption.15}{}}
\citation{bayindir2015}
\citation{davenport2012}
\citation{bayindir2015}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.3}GPUE memory footprint}{20}{subsection.1.3.3}\protected@file@percent }
\citation{o2017}
\citation{docs}
\citation{o2017,docs}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.4}Vortex tracking and highlighting}{21}{subsection.1.3.4}\protected@file@percent }
\newlabel{sec:tracking}{{1.3.4}{21}{Vortex tracking and highlighting}{subsection.1.3.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces An example phase plot of a condensate with four vortices. The inset shows the values of the grid around each vortex location and highlights where the sum is $2\pi $ for vortex tracking. \relax }}{22}{figure.caption.16}\protected@file@percent }
\newlabel{fig:phase}{{1.4}{22}{An example phase plot of a condensate with four vortices. The inset shows the values of the grid around each vortex location and highlights where the sum is $2\pi $ for vortex tracking. \relax }{figure.caption.16}{}}
\citation{villois2016}
\citation{guo2018}
\citation{canny1986}
\@writefile{lof}{\contentsline {figure}{\numberline {1.5}{\ignorespaces  An example of vortex highlighting with a Sobel filter. The upper left quadrant is the superfluid density with no modifications and the upper right quadrant is an isosurface of the density with an opacity of 0.6. Note here that if there is no opacity set, it is not possible to see the vortex because it is obscured by the outside boundary of the BEC. The lower right quadrant is the superfluid density after Sobel filtering and the bottom left quadrant is an isosuface on the Sobel filtered density. Here, we can easily create isosurfaces of vortices that would be occluded when using the density, alone. The scale varies depending on whether it is coloring the normalized wavefunction density or the filtered density. \relax }}{24}{figure.caption.17}\protected@file@percent }
\newlabel{fig:highlight}{{1.5}{24}{An example of vortex highlighting with a Sobel filter. The upper left quadrant is the superfluid density with no modifications and the upper right quadrant is an isosurface of the density with an opacity of 0.6. Note here that if there is no opacity set, it is not possible to see the vortex because it is obscured by the outside boundary of the BEC. The lower right quadrant is the superfluid density after Sobel filtering and the bottom left quadrant is an isosuface on the Sobel filtered density. Here, we can easily create isosurfaces of vortices that would be occluded when using the density, alone. The scale varies depending on whether it is coloring the normalized wavefunction density or the filtered density. \relax }{figure.caption.17}{}}
\citation{o2017,o2016,o2016topo}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.5}Energy calculation for superfluid simulations}{25}{subsection.1.3.5}\protected@file@percent }
\citation{bayindir2015}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.6}Similar software packages}{27}{subsection.1.3.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.7}Future direction and multi-GPU development}{27}{subsection.1.3.7}\protected@file@percent }
\newlabel{sec:multiGPU}{{1.3.7}{27}{Future direction and multi-GPU development}{subsection.1.3.7}{}}
\citation{harris2013}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}DistributedTranspose.jl}{28}{section.1.4}\protected@file@percent }
\newlabel{sec:DT}{{1.4}{28}{DistributedTranspose.jl}{section.1.4}{}}
\citation{jodra2015,el2008}
\citation{ruetsch2013}
\citation{merz2016}
\@writefile{toc}{\contentsline {section}{\numberline {1.5}Outlook}{29}{section.1.5}\protected@file@percent }
\@writefile{toc}{\vspace  {2em}}
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Simple vector additions in CUDA, OpenCL, and JuliaGPU}{31}{appendix.A}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{app:GPU}{{A}{31}{Simple vector additions in CUDA, OpenCL, and JuliaGPU}{appendix.A}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A.1}Vector addition with C++}{31}{section.A.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {A.2}Vector addition with CUDA}{33}{section.A.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {A.3}Vector addition with OpenCL}{35}{section.A.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {A.4}Julia}{39}{section.A.4}\protected@file@percent }
\@writefile{toc}{\vspace  {2em}}
\bibdata{Preamble/Thesis_bibliography}
\bibcite{kahle2019}{{1}{}{{}}{{}}}
\bibcite{gurd1988}{{2}{}{{}}{{}}}
\bibcite{czechowski2012}{{3}{}{{}}{{}}}
\bibcite{wittek2016}{{4}{}{{}}{{}}}
\bibcite{antoine2014}{{5}{}{{}}{{}}}
\bibcite{wittek2013}{{6}{}{{}}{{}}}
\bibcite{garland2008}{{7}{}{{}}{{}}}
\@writefile{toc}{\contentsline {chapter}{Bibliography}{41}{section*.18}\protected@file@percent }
\bibcite{lee2010}{{8}{}{{}}{{}}}
\bibcite{nickolls2010}{{9}{}{{}}{{}}}
\bibcite{CUDAPG}{{10}{}{{}}{{}}}
\bibcite{wienke2012}{{11}{}{{}}{{}}}
\bibcite{chandra2001}{{12}{}{{}}{{}}}
\bibcite{reyes2012}{{13}{}{{}}{{}}}
\bibcite{harris2013}{{14}{}{{}}{{}}}
\bibcite{foley2017}{{15}{}{{}}{{}}}
\bibcite{lonvcar2016}{{16}{}{{}}{{}}}
\bibcite{wang2013}{{17}{}{{}}{{}}}
\bibcite{besard2019}{{18}{}{{}}{{}}}
\bibcite{bezanson2017}{{19}{}{{}}{{}}}
\bibcite{besard2016}{{20}{}{{}}{{}}}
\bibcite{besard2018}{{21}{}{{}}{{}}}
\bibcite{o2017}{{22}{}{{}}{{}}}
\bibcite{schloss2018}{{23}{}{{}}{{}}}
\bibcite{cohen1991}{{24}{}{{}}{{}}}
\bibcite{reyes2011}{{25}{}{{}}{{}}}
\bibcite{bayindir2015}{{26}{}{{}}{{}}}
\bibcite{davenport2012}{{27}{}{{}}{{}}}
\bibcite{docs}{{28}{}{{}}{{}}}
\bibcite{villois2016}{{29}{}{{}}{{}}}
\bibcite{guo2018}{{30}{}{{}}{{}}}
\bibcite{canny1986}{{31}{}{{}}{{}}}
\bibcite{o2016}{{32}{}{{}}{{}}}
\bibcite{o2016topo}{{33}{}{{}}{{}}}
\bibcite{jodra2015}{{34}{}{{}}{{}}}
\bibcite{ruetsch2013}{{35}{}{{}}{{}}}
\bibcite{merz2016}{{36}{}{{}}{{}}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\@writefile{toc}{\vspace  {2em}}
